\newpage % Rozdziały zaczynamy od nowej strony.
\section{Wstęp}
Środowiska programistyczne ułatwiają i przyśpieszają pisanie kodu poprzez proponowanie 
słów kluczowych oraz nazw zdefiniowanych w programie. Dzięki tej funkcji programista nie musi pisać ręcznie 
w całości długiej nazwy zmiennej lub metody, a w niektórych przypadkach nie musi pisać jej wcale. 
Przykładem takiego zachowania jest zaproponowanie słowa kluczowego 'except' po słowie 'try' w języku Python,
lub propozycja nazwy zmiennej poprzez przechowywanie wszystkich zmiennych w słowniku.  
Jednak takie podejście wiążę się z wieloma wadami: 
\begin{itemize}
	\item Stworzenie takiego systemu uzupełniającego wiąże się ze zdefiniowaniem wielu skomplikowanych
	reguł, które różnią się dla każdego języka programowania. 
	\item System generujący propozycje nie uwzględnia kontekstu pisanego kodu. Na przykład w kodzie 
	aplikacji internetowej można zaobserwować wiele powtarzających się szablonów, które będą się różnić 
	od szablonów występujących w kodzie jądra systemu operacyjnego. 
	\item Podpowiedzi wygenerowane w ten sposób zazwyczaj ograniczają sie tylko do tylko jednego kolejnego słowa 
	\item W takim Systemie propozycje często są podawane w kolejności nie będącą zbyt pomocną dla programisty, 
	na przykład posortowane leksykograficznie. 
\end{itemize}

\subsection {Problem}
Istnieje wiele rodzajów uzupełniania kodu: 
\begin{itemize}
	\item przewidzenie kolejnego słowa (tokenu) 
	\item przewidzenie dłuższej sekwencji słów (na przykład dokończanie linijki)
	\item generowanie funkcji na podstawie jej opisu w komentarzu
	\item uzupełnianie brakujących linii lub tokenów w zaznaczonych miejscach w kodzie
\end{itemize}
W tej pracy skupiam się na pierwszym z rodzajów tego problemu. Moim celem jest stworzenie systemu, który rozwiąże 
wcześniej wymienione problemy oraz sprawdzenie czy zaproponowane przeze mnie rozwiązanie jest akceptowalne następnie 
zaimplementowanie go jako wtyczka do środowiska SublimeText. 

\subsection {Kod a język naturalny}
Metody statystyczne oraz rekurencyjne sieci neuronowe osiągają bardzo dobre rezultaty w generowaniu tekstów. 
Języki programowania dzielą wiele cech wspólnych z językiem naturalnym. Oba są używane do opisywania algorytmów 
w skończonej liczbie kroków. Logika stojąca za wyrażaniem kolejnych kroków jest taka sama. Oba języki używane są 
do komunikacji. Naturalny używany pomiędzy ludźmi, natomiast programowania między człowiekiem a komputerem. 
Jednak najważniejszą łączącą je cechą jest ich powtarzalność. W obu z dużym prawdopodobieństwem po jednym 
słowie może wystąpić tyko niewielki zbiór innych słów. 

\subsection {Wyzwania}
Głównym wyzwaniem oraz detalem różniącym języki programowania od języków naturalnych jest możliwość nadawania dowolnych
nazw obiektom oraz metodom przez co nie można objąć wszystkich słów w słowniku danych treningowych. Słowa tego typu 
nazywane są słowami poza słownikiem. Zwiększanie wielkości słownika nigdy nie obejmie wszystkich możliwych nazw natomiast 
bardzo spowolni ostatni krok algorytmu, którym jest obliczenie wyznaczenie funkcji softmax. Jak zostało pokazane w publikacji 
\cite{hellendoorn} od pewnego momentu większy rozmiar słownika zaczyna wpływać negatywnie na skuteczność modelu. 

Nadmierne dopasowanie modelu do danych treningowych może wystąpić przy zbyt długim treningu. Taki model 
zacznie dawać bardzo dobre predykcje na zbiorze treningowym jednak bardzo słabo poradzi sobie na zbiorze 
walidacyjnym. Zamiast zgeneralizować problem model nauczy się danych treningowych 'na pamięć'. 

Przewidywanie kilku tokenów w przód. Omawiany w tej pracy model jest w stanie przewidywać kilka na raz 
jednak znacząco utrudnia to zadanie inżynierskie oraz miałoby negatywny wpływ na korzystanie ze wtyczki 
w warunkach rzeczywistych. Skuteczność modelu o skuteczności wynoszącej na przykład {70\%} dla pojedyńczych 
tokenów przy próbie przewidzenia 3 tokenów na raz spadłaby do \begin{math}0.7^3 = 0.343\end{math}, co było by nieakceptowalne 
w warunkach rzeczywistych. 

\subsection {Zastosowania}
Główny zastosowaniem tworzonego systemu jest usprawnienie pracy programisty. Jednak przy założeniu, że model działa dobrze 
istnieje więcej przypadków użycia: 
\begin{itemize}
	\item Tworzenie kodu na urządzeniu mobilnym. W dzisiejszych czasach urządzenia mobilne mają ogromne możliwości. 
	Jedyną rzeczą, która je powstrzymuje przed użyciem ich w celu rozwoju oprogramowania jest mała klawiatura dotykowa, nie
	udostępniająca szybkiego dostępu do znaków specjalnych. Wtyczka mogłaby znacznie usprawnić pisanie przez przewidywanie znaków 
	specjalnych (z czym jak pokażę później radzi sobie bardzo dobrze), jak i długich, niewygodnych do napisania na małej dotykowej klawiaturze nazw.

	\item Szukanie błędów w kodzie. Model może obliczyć prawdopodobieństwo wystąpienie następnego tokenu po czym sprawdzić czy 
	pokrywa się on z faktycznie występującym tokenem. W ten sposób możemy określić miejsce w kodzie w którym możemy się 
	spodziewać, że został popełniony błąd. 

	\item Kompresja kodu. Modele Sequence2Sequence sprawdzają się w zadaniu kompresji. Model mógłby nauczyć się wygenerować resztę programu 
	na podstawie kilku pierwszych tokenów. W ten sposób zamiast zapisywać cały kod źródłowy moglibyśmy zapamiętywać jedynie kilka 
	krótkie sekwencje. 
\end{itemize}

\subsection {Pytania badawcze}
Czy rekurencyjne sieci neuronowe nadają się do wykonywania predykcji w kodzie?
\subsubsection {Inne pytania}
\begin{itemize}
	\item Jaki model radzi sobie najlepiej z wykonywaniem predykcji w kodzie? 
	\item Jaki jest wpływ długości sekwencji na predykcje? 
	\item Czy wielkość słownika ma wpływ na predykcje? 
	\item Jaka liczba warstw rekurencyjnej sieci neuronowej radzi sobie najlepiej? 
	\item Jaki układ warstw poradzi sobie najlepiej w zadaniu. 
\end{itemize} 


% \begin{figure}[!h]
% 	% Znacznik \caption oprócz podpisu służy również do wygenerowania numeru obrazka;
% 	\caption{Tradycyjne godło Politechniki Warszawskiej}
% 	% dlatego zawsze pamiętaj używać najpierw \caption, a potem \label
%     \label{fig:tradycyjne-logo-pw}
%     % Zamiast width można też użyć height, etc. 
%     \centering \includegraphics[width=0.5\linewidth]{logopw.png}
% \end{figure}

% \begin{figure}[!h]
% 	\caption{Współczesne logo Politechniki Warszawskiej}
% 	\label{fig:nowe-logo-pw}
% 	\centering \includegraphics[width=0.5\linewidth]{logopw2.png}
% \end{figure}
% % \lipsum[4-6] Reference to image \ref{fig:nowe-logo-pw}. 
