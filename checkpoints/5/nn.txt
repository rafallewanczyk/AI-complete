Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
embedding (Embedding)        (128, None, 32)           640032
_________________________________________________________________
lstm (LSTM)                  (128, None, 128)          82432
_________________________________________________________________
lstm_1 (LSTM)                (128, None, 128)          131584
_________________________________________________________________
dense (Dense)                (128, None, 20001)        2580129
=================================================================
Total params: 3,434,177
Trainable params: 3,434,177
Non-trainable params: 0

vocab_size = 20001
embedding_dim = 32 #CONST
rnn_units = 128
batch_size = 128 #CONST
win_size = 5

    def build_model(self):
        self.model = Sequential()
        self.model.add(Embedding(self.vocab_size, self.embedding_dim, batch_input_shape=[self.batch_size, None]))
        # self.model.add(Convolution1D(self.embedding_dim, kernel_size=1, activation='relu'))
        self.model.add(
            LSTM(self.rnn_units, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform'))
        self.model.add(
            LSTM(self.rnn_units, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform'))
        # self.model.add(
        #     GRU(self.rnn_units, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform'))
        self.model.add(Dense(self.vocab_size))