Model: "sequential_2"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding_2 (Embedding)      (128, None, 32)           640032    
_________________________________________________________________
lstm_2 (LSTM)                (128, None, 128)          82432     
_________________________________________________________________
dense_2 (Dense)              (128, None, 20001)        2580129   
=================================================================
Total params: 3,302,593
Trainable params: 3,302,593
Non-trainable params: 0
_________________________________________________________________

vocab_size = 20001
embedding_dim = 32 #CONST
rnn_units = 128
batch_size = 128 #CONST
win_size = 5

    def build_model(self):
        self.model = Sequential()
        self.model.add(Embedding(self.vocab_size, self.embedding_dim, batch_input_shape=[self.batch_size, None]))
        # self.model.add(Convolution1D(self.embedding_dim, kernel_size=1, activation='relu'))
        self.model.add(
            LSTM(self.rnn_units, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform'))
        # self.model.add(
        #     GRU(self.rnn_units, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform'))
        self.model.add(Dense(self.vocab_size))

accuracies:
	top_1: 0.23
	top_3: 0.46
	top_5: 0.59
	ranked_5: 0.36
	ranked_10: 0.37